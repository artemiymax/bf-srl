{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interstate-testament",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import gym\n",
    "from websocket import create_connection\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comic-overview",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "demographic-webmaster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class UnrealAgentsEnvironment(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, exec_path, port):\n",
    "        super(UnrealAgentsEnvironment, self).__init__()\n",
    "        \n",
    "        self.__initialize_unreal_exec(exec_path, port)\n",
    "\n",
    "    def step(self, action):\n",
    "        step_info = self.__step(action)\n",
    "        return np.array(step_info[0]['observations']), step_info[0]['reward'], step_info[0]['done'], step_info[0]['info']\n",
    "\n",
    "    def reset(self):\n",
    "        spet_info = self.__reset()\n",
    "        return spet_info[0]['observations']\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return 0\n",
    "\n",
    "    def close (self):\n",
    "        command = { \"type\": \"close\", \"data\": \"\" }      \n",
    "        self.connection.send(json.dumps(command))\n",
    "    \n",
    "    def __reset(self):\n",
    "        command = { \"type\": \"reset\", \"data\": \"\" }\n",
    "        \n",
    "        self.connection.send(json.dumps(command))        \n",
    "        step_info = json.loads(self.connection.recv())\n",
    "        \n",
    "        for step in step_info:\n",
    "            step['info'] = {}\n",
    "        \n",
    "        return step_info\n",
    "    \n",
    "    def __step(self, action):\n",
    "        actions = {}\n",
    "        agent_action = {\"discreteActions\": [action], \"continuousActions\": []}\n",
    "        actions[self.agent] = agent_action\n",
    "            \n",
    "        command = { \"type\": \"step\", \"data\": json.dumps(actions, cls=NpEncoder) }\n",
    "        self.connection.send(json.dumps(command))\n",
    "\n",
    "        step_info = json.loads(self.connection.recv())\n",
    "        \n",
    "        for step in step_info:\n",
    "            step['info'] = {}\n",
    "        \n",
    "        return step_info\n",
    "    \n",
    "    def __initialize_unreal_exec(self, exec_path, port):\n",
    "        game_instance = subprocess.Popen([exec_path, '-windowed', '-ResX=640', '-ResY=360', \"-proxyPort={0}\".format(port), \"-recordMetrics\", \"-flushInterval=10\"])\n",
    "        \n",
    "        self.connection = None\n",
    "        while_timeout = time.time() + 120\n",
    "        while self.connection == None and time.time() < while_timeout:\n",
    "            try:\n",
    "                self.connection = create_connection(\"ws://localhost:{0}/ws\".format(port))\n",
    "            except:\n",
    "                if game_instance.poll() != None:\n",
    "                    raise\n",
    "                print(\"Retrying environment connection...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "variable-switch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class UnrealAgentsCartPole(UnrealAgentsEnvironment):\n",
    "    \n",
    "    def __init__(self, exec_path, port):\n",
    "        super(UnrealAgentsCartPole, self).__init__(exec_path, port)\n",
    "        \n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        \n",
    "        high = np.array([50,\n",
    "                         np.finfo(np.float32).max,\n",
    "                         15,\n",
    "                         np.finfo(np.float32).max],\n",
    "                        dtype=np.float32)\n",
    "        \n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "        self.agent = \"Cart1\"\n",
    "        \n",
    "class UnrealAgentsBallPusher(UnrealAgentsEnvironment):\n",
    "    \n",
    "    def __init__(self, exec_path, port):\n",
    "        super(UnrealAgentsBallPusher, self).__init__(exec_path, port)\n",
    "        \n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(144,), dtype=np.float32)\n",
    "        self.agent = \"BallPusherAgent1_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-valentine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CartPole Learning\n",
    "env = make_vec_env(UnrealAgentsCartPole, n_envs=1, env_kwargs={'port': 8008, 'exec_path': 'PATH_TO_EXE'})\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log='PATH_TO_LOG')\n",
    "model.learn(total_timesteps=100000, tb_log_name = 'ppo_cartpole_1')\n",
    "model.save(\"ppo_cartpole_1\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-marsh",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CartPole Inference\n",
    "model = PPO.load(\"ppo_cartpole_1\")\n",
    "env = make_vec_env(UnrealAgentsCartPole, n_envs=1, env_kwargs={'port': 8008, 'exec_path': 'PATH_TO_EXE'})\n",
    "obs = env.reset()\n",
    "for i in range(100000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-cameroon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BallPusher Learning\n",
    "env = make_vec_env(UnrealAgentsBallPusher, n_envs=1, env_kwargs={'port': 8008, 'exec_path': 'PATH_TO_EXE'})\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log='PATH_TO_LOG')\n",
    "model.learn(total_timesteps=100000, tb_log_name = 'ppo_ballpusher_1')\n",
    "model.save(\"ppo_ballpusher_1\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-cleaning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BallPusher Inference\n",
    "model = PPO.load(\"ppo_ballpusher_1\")\n",
    "env = make_vec_env(UnrealAgentsBallPusher, n_envs=1, env_kwargs={'port': 8008, 'exec_path': 'PATH_TO_EXE'})\n",
    "obs = env.reset()\n",
    "for i in range(100000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
